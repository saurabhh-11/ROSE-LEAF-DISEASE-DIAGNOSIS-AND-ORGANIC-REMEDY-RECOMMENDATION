{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of BLACK_SPOT leaf images in training set: 700\n",
      "Number of DOWNY_MILDEW leaf images in training set: 700\n",
      "Number of FRESH_LEAF leaf images in training set: 700\n",
      "Number of POWDERY_MILDEW leaf images in training set: 700\n",
      "Number of ROSE_MOSAIC leaf images in training set: 700\n",
      "Number of ROSE_RUST leaf images in training set: 700\n",
      "Number of ROSE_SLUG leaf images in training set: 700\n",
      "========================================================\n",
      "Number of BLACK_SPOT leaf images in test set: 150\n",
      "Number of DOWNY_MILDEW leaf images in test set: 150\n",
      "Number of FRESH_LEAF leaf images in test set: 150\n",
      "Number of POWDERY_MILDEW leaf images in test set: 150\n",
      "Number of ROSE_MOSAIC leaf images in test set: 150\n",
      "Number of ROSE_RUST leaf images in test set: 150\n",
      "Number of ROSE_SLUG leaf images in test set: 150\n",
      "========================================================\n",
      "Number of BLACK_SPOT leaf images in validation set: 150\n",
      "Number of DOWNY_MILDEW leaf images in validation set: 150\n",
      "Number of FRESH_LEAF leaf images in validation set: 150\n",
      "Number of POWDERY_MILDEW leaf images in validation set: 150\n",
      "Number of ROSE_MOSAIC leaf images in validation set: 150\n",
      "Number of ROSE_RUST leaf images in validation set: 150\n",
      "Number of ROSE_SLUG leaf images in validation set: 150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def total_files(folder_path):\n",
    "    num_files = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "    return num_files\n",
    "\n",
    "# Paths to your training, test, and validation directories\n",
    "train_dir = \"D:/project_1/IMPLEMENTATION/OG Dataset/train\"\n",
    "test_dir = \"D:/project_1/IMPLEMENTATION/OG Dataset/test\"\n",
    "valid_dir = \"D:/project_1/IMPLEMENTATION/OG Dataset/validation\"\n",
    "# Class names\n",
    "classes = ['BLACK_SPOT', 'DOWNY_MILDEW', 'FRESH_LEAF', 'POWDERY_MILDEW', 'ROSE_MOSAIC', 'ROSE_RUST', 'ROSE_SLUG']\n",
    "\n",
    "# Count images in training set\n",
    "for class_name in classes:\n",
    "    train_path = os.path.join(train_dir, class_name)\n",
    "    print(f\"Number of {class_name} leaf images in training set:\", total_files(train_path))\n",
    "\n",
    "print(\"========================================================\")\n",
    "\n",
    "# Count images in test set\n",
    "for class_name in classes:\n",
    "    test_path = os.path.join(test_dir, class_name)\n",
    "    print(f\"Number of {class_name} leaf images in test set:\", total_files(test_path))\n",
    "\n",
    "print(\"========================================================\")\n",
    "\n",
    "# Count images in validation set\n",
    "for class_name in classes:\n",
    "    valid_path = os.path.join(valid_dir, class_name)\n",
    "    print(f\"Number of {class_name} leaf images in validation set:\", total_files(valid_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset paths\n",
    "train_dir = \"D:/project_1/IMPLEMENTATION/OG Dataset/train\"\n",
    "test_dir = \"D:/project_1/IMPLEMENTATION/OG Dataset/test\"\n",
    "valid_dir = \"D:/project_1/IMPLEMENTATION/OG Dataset/validation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_dict = {\n",
    "    0: 'BLACK_SPOT',\n",
    "    1: 'DOWNY_MILDEW',\n",
    "    2: 'FRESH_LEAF',\n",
    "    3: 'POWDERY_MILDEW',\n",
    "    4: 'ROSE_MOSAIC',\n",
    "    5: 'ROSE_RUST',\n",
    "    6: 'ROSE_SLUG'\n",
    "}\n",
    "num_classes = len(disease_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4900 images belonging to 7 classes.\n",
      "Found 1050 images belonging to 7 classes.\n",
      "Found 1050 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),  \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(224, 224),  \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),  \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_folder = 'confusion_matrices'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Hyperparameters to experiment with\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "num_layers = 4\n",
    "neurons = 128\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "experiment_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_cnn(activation, optimizer, num_layers, neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    for _ in range(num_layers - 1):  # Add additional layers\n",
    "        model.add(Conv2D(32, (3, 3), activation=activation, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Ensure num_classes is defined\n",
    "\n",
    "    # Select optimizer\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=1e-4)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=0.01)\n",
    "    else:\n",
    "        opt = RMSprop(learning_rate=0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,214,442</span> (16.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,214,442\u001b[0m (16.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,871</span> (644.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,871\u001b[0m (644.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with relu, adam, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.4498 - loss: 1.6667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 582ms/step - accuracy: 0.4502 - loss: 1.6652 - val_accuracy: 0.4210 - val_loss: 2.0421\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 571ms/step - accuracy: 0.7204 - loss: 0.7298 - val_accuracy: 0.8333 - val_loss: 0.4795\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 613ms/step - accuracy: 0.7934 - loss: 0.5586 - val_accuracy: 0.8571 - val_loss: 0.3579\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 617ms/step - accuracy: 0.8408 - loss: 0.4413 - val_accuracy: 0.8781 - val_loss: 0.2900\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 373ms/step - accuracy: 0.8666 - loss: 0.3601 - val_accuracy: 0.8790 - val_loss: 0.2951\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 289ms/step - accuracy: 0.8707 - loss: 0.3303 - val_accuracy: 0.8990 - val_loss: 0.2602\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 381ms/step - accuracy: 0.8965 - loss: 0.2771 - val_accuracy: 0.9114 - val_loss: 0.2388\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 233ms/step - accuracy: 0.8999 - loss: 0.2650\n",
      "Accuracy of relu_adam_4_128 model: 0.892380952835083\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 127ms/step\n",
      "{'0': {'precision': 0.1962025316455696, 'recall': 0.20666666666666667, 'f1-score': 0.2012987012987013, 'support': 150.0}, '1': {'precision': 0.18309859154929578, 'recall': 0.17333333333333334, 'f1-score': 0.1780821917808219, 'support': 150.0}, '2': {'precision': 0.183206106870229, 'recall': 0.16, 'f1-score': 0.1708185053380783, 'support': 150.0}, '3': {'precision': 0.12987012987012986, 'recall': 0.13333333333333333, 'f1-score': 0.13157894736842105, 'support': 150.0}, '4': {'precision': 0.16666666666666666, 'recall': 0.16666666666666666, 'f1-score': 0.16666666666666666, 'support': 150.0}, '5': {'precision': 0.1746987951807229, 'recall': 0.19333333333333333, 'f1-score': 0.18354430379746836, 'support': 150.0}, '6': {'precision': 0.1476510067114094, 'recall': 0.14666666666666667, 'f1-score': 0.14715719063545152, 'support': 150.0}, 'accuracy': 0.16857142857142857, 'macro avg': {'precision': 0.16877054692771762, 'recall': 0.16857142857142857, 'f1-score': 0.1684495009836584, 'support': 1050.0}, 'weighted avg': {'precision': 0.16877054692771762, 'recall': 0.16857142857142857, 'f1-score': 0.16844950098365843, 'support': 1050.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15908\\2107074128.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with relu, sgd, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 472ms/step - accuracy: 0.4869 - loss: 1.6177 - val_accuracy: 0.3486 - val_loss: 2.1776\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 673ms/step - accuracy: 0.7321 - loss: 0.6819 - val_accuracy: 0.6276 - val_loss: 1.3384\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 619ms/step - accuracy: 0.7865 - loss: 0.5441 - val_accuracy: 0.7990 - val_loss: 0.5051\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 590ms/step - accuracy: 0.8072 - loss: 0.4783 - val_accuracy: 0.5695 - val_loss: 1.6451\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 600ms/step - accuracy: 0.8291 - loss: 0.4400 - val_accuracy: 0.7210 - val_loss: 0.7907\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 616ms/step - accuracy: 0.8676 - loss: 0.3353 - val_accuracy: 0.8829 - val_loss: 0.3503\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 659ms/step - accuracy: 0.8762 - loss: 0.3211 - val_accuracy: 0.9057 - val_loss: 0.2456\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 360ms/step - accuracy: 0.8844 - loss: 0.2633\n",
      "Accuracy of relu_sgd_4_128 model: 0.8847619295120239\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 356ms/step\n",
      "{'0': {'precision': 0.14606741573033707, 'recall': 0.08666666666666667, 'f1-score': 0.1087866108786611, 'support': 150.0}, '1': {'precision': 0.14556962025316456, 'recall': 0.15333333333333332, 'f1-score': 0.14935064935064934, 'support': 150.0}, '2': {'precision': 0.15023474178403756, 'recall': 0.21333333333333335, 'f1-score': 0.1763085399449036, 'support': 150.0}, '3': {'precision': 0.12, 'recall': 0.12, 'f1-score': 0.12, 'support': 150.0}, '4': {'precision': 0.14583333333333334, 'recall': 0.14, 'f1-score': 0.14285714285714285, 'support': 150.0}, '5': {'precision': 0.14965986394557823, 'recall': 0.14666666666666667, 'f1-score': 0.14814814814814814, 'support': 150.0}, '6': {'precision': 0.12751677852348994, 'recall': 0.12666666666666668, 'f1-score': 0.12709030100334448, 'support': 150.0}, 'accuracy': 0.14095238095238094, 'macro avg': {'precision': 0.1406973933671344, 'recall': 0.14095238095238097, 'f1-score': 0.13893448459754992, 'support': 1050.0}, 'weighted avg': {'precision': 0.14069739336713438, 'recall': 0.14095238095238094, 'f1-score': 0.13893448459754992, 'support': 1050.0}}\n",
      "Training model with relu, rmsprop, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 663ms/step - accuracy: 0.4828 - loss: 2.6272 - val_accuracy: 0.4248 - val_loss: 2.8468\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 657ms/step - accuracy: 0.6495 - loss: 1.0569 - val_accuracy: 0.7810 - val_loss: 0.6424\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 658ms/step - accuracy: 0.7414 - loss: 0.7843 - val_accuracy: 0.5076 - val_loss: 3.8217\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 514ms/step - accuracy: 0.7675 - loss: 0.7310 - val_accuracy: 0.8029 - val_loss: 0.6362\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 365ms/step - accuracy: 0.8042 - loss: 0.6104 - val_accuracy: 0.8171 - val_loss: 0.6234\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 340ms/step - accuracy: 0.8156 - loss: 0.5946 - val_accuracy: 0.8181 - val_loss: 0.5405\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 340ms/step - accuracy: 0.8223 - loss: 0.5438 - val_accuracy: 0.8657 - val_loss: 0.4338\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - accuracy: 0.8829 - loss: 0.5236\n",
      "Accuracy of relu_rmsprop_4_128 model: 0.8638095259666443\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 156ms/step\n",
      "{'0': {'precision': 0.0975609756097561, 'recall': 0.10666666666666667, 'f1-score': 0.10191082802547771, 'support': 150.0}, '1': {'precision': 0.15343915343915343, 'recall': 0.19333333333333333, 'f1-score': 0.1710914454277286, 'support': 150.0}, '2': {'precision': 0.1926605504587156, 'recall': 0.14, 'f1-score': 0.16216216216216217, 'support': 150.0}, '3': {'precision': 0.12962962962962962, 'recall': 0.14, 'f1-score': 0.1346153846153846, 'support': 150.0}, '4': {'precision': 0.11678832116788321, 'recall': 0.10666666666666667, 'f1-score': 0.11149825783972125, 'support': 150.0}, '5': {'precision': 0.18518518518518517, 'recall': 0.16666666666666666, 'f1-score': 0.17543859649122806, 'support': 150.0}, '6': {'precision': 0.14285714285714285, 'recall': 0.14666666666666667, 'f1-score': 0.14473684210526316, 'support': 150.0}, 'accuracy': 0.14285714285714285, 'macro avg': {'precision': 0.14544585119249515, 'recall': 0.14285714285714285, 'f1-score': 0.1430647880952808, 'support': 1050.0}, 'weighted avg': {'precision': 0.14544585119249512, 'recall': 0.14285714285714285, 'f1-score': 0.1430647880952808, 'support': 1050.0}}\n",
      "Training model with tanh, adam, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 342ms/step - accuracy: 0.5341 - loss: 1.3072 - val_accuracy: 0.5276 - val_loss: 1.4391\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 360ms/step - accuracy: 0.7154 - loss: 0.7567 - val_accuracy: 0.8067 - val_loss: 0.5225\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 340ms/step - accuracy: 0.7665 - loss: 0.6306 - val_accuracy: 0.8524 - val_loss: 0.3778\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 353ms/step - accuracy: 0.7979 - loss: 0.5247 - val_accuracy: 0.8810 - val_loss: 0.3101\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 325ms/step - accuracy: 0.8409 - loss: 0.4410 - val_accuracy: 0.8190 - val_loss: 0.5370\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 346ms/step - accuracy: 0.8398 - loss: 0.4083 - val_accuracy: 0.8895 - val_loss: 0.2890\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 345ms/step - accuracy: 0.8583 - loss: 0.3689 - val_accuracy: 0.8819 - val_loss: 0.3105\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - accuracy: 0.8718 - loss: 0.3514\n",
      "Accuracy of tanh_adam_4_128 model: 0.8771428465843201\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step\n",
      "{'0': {'precision': 0.15789473684210525, 'recall': 0.14, 'f1-score': 0.14840989399293286, 'support': 150.0}, '1': {'precision': 0.12025316455696203, 'recall': 0.12666666666666668, 'f1-score': 0.12337662337662338, 'support': 150.0}, '2': {'precision': 0.1366906474820144, 'recall': 0.12666666666666668, 'f1-score': 0.1314878892733564, 'support': 150.0}, '3': {'precision': 0.1242603550295858, 'recall': 0.14, 'f1-score': 0.13166144200626959, 'support': 150.0}, '4': {'precision': 0.1165644171779141, 'recall': 0.12666666666666668, 'f1-score': 0.12140575079872204, 'support': 150.0}, '5': {'precision': 0.12949640287769784, 'recall': 0.12, 'f1-score': 0.1245674740484429, 'support': 150.0}, '6': {'precision': 0.1342281879194631, 'recall': 0.13333333333333333, 'f1-score': 0.13377926421404682, 'support': 150.0}, 'accuracy': 0.13047619047619047, 'macro avg': {'precision': 0.1313411302693918, 'recall': 0.1304761904761905, 'f1-score': 0.1306697625300563, 'support': 1050.0}, 'weighted avg': {'precision': 0.1313411302693918, 'recall': 0.13047619047619047, 'f1-score': 0.1306697625300563, 'support': 1050.0}}\n",
      "Training model with tanh, sgd, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 343ms/step - accuracy: 0.5249 - loss: 1.3494 - val_accuracy: 0.6448 - val_loss: 0.8369\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 338ms/step - accuracy: 0.6973 - loss: 0.8235 - val_accuracy: 0.8133 - val_loss: 0.5079\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 346ms/step - accuracy: 0.7614 - loss: 0.5919 - val_accuracy: 0.7629 - val_loss: 0.6118\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 346ms/step - accuracy: 0.7984 - loss: 0.4982 - val_accuracy: 0.7190 - val_loss: 0.7404\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 341ms/step - accuracy: 0.8251 - loss: 0.4438 - val_accuracy: 0.8676 - val_loss: 0.3204\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 344ms/step - accuracy: 0.8493 - loss: 0.3814 - val_accuracy: 0.8819 - val_loss: 0.3201\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 334ms/step - accuracy: 0.8623 - loss: 0.3353 - val_accuracy: 0.8390 - val_loss: 0.4136\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - accuracy: 0.8412 - loss: 0.4122\n",
      "Accuracy of tanh_sgd_4_128 model: 0.8257142901420593\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step\n",
      "{'0': {'precision': 0.13253012048192772, 'recall': 0.14666666666666667, 'f1-score': 0.13924050632911392, 'support': 150.0}, '1': {'precision': 0.15846994535519127, 'recall': 0.19333333333333333, 'f1-score': 0.17417417417417416, 'support': 150.0}, '2': {'precision': 0.1506849315068493, 'recall': 0.07333333333333333, 'f1-score': 0.09865470852017937, 'support': 150.0}, '3': {'precision': 0.15476190476190477, 'recall': 0.17333333333333334, 'f1-score': 0.16352201257861634, 'support': 150.0}, '4': {'precision': 0.1393939393939394, 'recall': 0.15333333333333332, 'f1-score': 0.14603174603174604, 'support': 150.0}, '5': {'precision': 0.11188811188811189, 'recall': 0.10666666666666667, 'f1-score': 0.10921501706484642, 'support': 150.0}, '6': {'precision': 0.10526315789473684, 'recall': 0.10666666666666667, 'f1-score': 0.10596026490066225, 'support': 150.0}, 'accuracy': 0.1361904761904762, 'macro avg': {'precision': 0.13614173018323733, 'recall': 0.1361904761904762, 'f1-score': 0.13382834708561978, 'support': 1050.0}, 'weighted avg': {'precision': 0.13614173018323733, 'recall': 0.1361904761904762, 'f1-score': 0.13382834708561978, 'support': 1050.0}}\n",
      "Training model with tanh, rmsprop, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 352ms/step - accuracy: 0.4283 - loss: 1.8244 - val_accuracy: 0.4771 - val_loss: 1.6211\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 343ms/step - accuracy: 0.5767 - loss: 1.1927 - val_accuracy: 0.6362 - val_loss: 0.9812\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 348ms/step - accuracy: 0.6408 - loss: 0.9716 - val_accuracy: 0.5714 - val_loss: 1.2383\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 284ms/step - accuracy: 0.6794 - loss: 0.8798 - val_accuracy: 0.6057 - val_loss: 1.0866\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 339ms/step - accuracy: 0.7039 - loss: 0.7870 - val_accuracy: 0.5990 - val_loss: 1.1172\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 233ms/step - accuracy: 0.7244 - loss: 0.7169 - val_accuracy: 0.6867 - val_loss: 0.8735\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 235ms/step - accuracy: 0.7570 - loss: 0.6274 - val_accuracy: 0.6543 - val_loss: 0.9150\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - accuracy: 0.6535 - loss: 0.9960\n",
      "Accuracy of tanh_rmsprop_4_128 model: 0.6476190686225891\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 118ms/step\n",
      "{'0': {'precision': 0.14, 'recall': 0.04666666666666667, 'f1-score': 0.07, 'support': 150.0}, '1': {'precision': 0.13333333333333333, 'recall': 0.14666666666666667, 'f1-score': 0.13968253968253969, 'support': 150.0}, '2': {'precision': 0.14320388349514562, 'recall': 0.3933333333333333, 'f1-score': 0.2099644128113879, 'support': 150.0}, '3': {'precision': 0.13095238095238096, 'recall': 0.07333333333333333, 'f1-score': 0.09401709401709402, 'support': 150.0}, '4': {'precision': 0.16541353383458646, 'recall': 0.14666666666666667, 'f1-score': 0.15547703180212014, 'support': 150.0}, '5': {'precision': 0.1, 'recall': 0.03333333333333333, 'f1-score': 0.05, 'support': 150.0}, '6': {'precision': 0.14743589743589744, 'recall': 0.15333333333333332, 'f1-score': 0.1503267973856209, 'support': 150.0}, 'accuracy': 0.1419047619047619, 'macro avg': {'precision': 0.13719128986447768, 'recall': 0.1419047619047619, 'f1-score': 0.12420969652839467, 'support': 1050.0}, 'weighted avg': {'precision': 0.13719128986447768, 'recall': 0.1419047619047619, 'f1-score': 0.12420969652839466, 'support': 1050.0}}\n",
      "Training model with sigmoid, adam, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 342ms/step - accuracy: 0.5203 - loss: 1.2896 - val_accuracy: 0.1486 - val_loss: 2.2950\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 345ms/step - accuracy: 0.7332 - loss: 0.7194 - val_accuracy: 0.6933 - val_loss: 0.7776\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 279ms/step - accuracy: 0.7677 - loss: 0.6131 - val_accuracy: 0.8295 - val_loss: 0.4726\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 334ms/step - accuracy: 0.8118 - loss: 0.5168 - val_accuracy: 0.8819 - val_loss: 0.3868\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 633ms/step - accuracy: 0.8481 - loss: 0.4414 - val_accuracy: 0.8524 - val_loss: 0.3823\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 628ms/step - accuracy: 0.8579 - loss: 0.4224 - val_accuracy: 0.8610 - val_loss: 0.3650\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 561ms/step - accuracy: 0.8496 - loss: 0.4115 - val_accuracy: 0.8771 - val_loss: 0.3407\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.8852 - loss: 0.3301\n",
      "Accuracy of sigmoid_adam_4_128 model: 0.8790476322174072\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step\n",
      "{'0': {'precision': 0.17073170731707318, 'recall': 0.09333333333333334, 'f1-score': 0.1206896551724138, 'support': 150.0}, '1': {'precision': 0.13291139240506328, 'recall': 0.14, 'f1-score': 0.13636363636363635, 'support': 150.0}, '2': {'precision': 0.12376237623762376, 'recall': 0.16666666666666666, 'f1-score': 0.14204545454545456, 'support': 150.0}, '3': {'precision': 0.1568627450980392, 'recall': 0.16, 'f1-score': 0.15841584158415842, 'support': 150.0}, '4': {'precision': 0.14583333333333334, 'recall': 0.14, 'f1-score': 0.14285714285714285, 'support': 150.0}, '5': {'precision': 0.147239263803681, 'recall': 0.16, 'f1-score': 0.15335463258785942, 'support': 150.0}, '6': {'precision': 0.10135135135135136, 'recall': 0.1, 'f1-score': 0.10067114093959731, 'support': 150.0}, 'accuracy': 0.13714285714285715, 'macro avg': {'precision': 0.13981316707802358, 'recall': 0.13714285714285715, 'f1-score': 0.13634250057860897, 'support': 1050.0}, 'weighted avg': {'precision': 0.13981316707802358, 'recall': 0.13714285714285715, 'f1-score': 0.13634250057860897, 'support': 1050.0}}\n",
      "Training model with sigmoid, sgd, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 604ms/step - accuracy: 0.4936 - loss: 1.3505 - val_accuracy: 0.3152 - val_loss: 1.7266\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 622ms/step - accuracy: 0.7054 - loss: 0.8058 - val_accuracy: 0.6143 - val_loss: 1.0091\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 562ms/step - accuracy: 0.7345 - loss: 0.6963 - val_accuracy: 0.4800 - val_loss: 1.5112\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 622ms/step - accuracy: 0.7849 - loss: 0.5767 - val_accuracy: 0.7962 - val_loss: 0.5677\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 625ms/step - accuracy: 0.8052 - loss: 0.5336 - val_accuracy: 0.8257 - val_loss: 0.4437\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 304ms/step - accuracy: 0.8376 - loss: 0.4514 - val_accuracy: 0.8410 - val_loss: 0.4263\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 279ms/step - accuracy: 0.8315 - loss: 0.4522 - val_accuracy: 0.8267 - val_loss: 0.4741\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.8024 - loss: 0.5184\n",
      "Accuracy of sigmoid_sgd_4_128 model: 0.808571457862854\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step\n",
      "{'0': {'precision': 0.08235294117647059, 'recall': 0.04666666666666667, 'f1-score': 0.059574468085106386, 'support': 150.0}, '1': {'precision': 0.1297709923664122, 'recall': 0.11333333333333333, 'f1-score': 0.12099644128113879, 'support': 150.0}, '2': {'precision': 0.13333333333333333, 'recall': 0.12, 'f1-score': 0.12631578947368421, 'support': 150.0}, '3': {'precision': 0.09580838323353294, 'recall': 0.10666666666666667, 'f1-score': 0.10094637223974763, 'support': 150.0}, '4': {'precision': 0.17391304347826086, 'recall': 0.18666666666666668, 'f1-score': 0.18006430868167203, 'support': 150.0}, '5': {'precision': 0.12796208530805686, 'recall': 0.18, 'f1-score': 0.14958448753462603, 'support': 150.0}, '6': {'precision': 0.13125, 'recall': 0.14, 'f1-score': 0.13548387096774195, 'support': 150.0}, 'accuracy': 0.12761904761904763, 'macro avg': {'precision': 0.12491296841372382, 'recall': 0.12761904761904763, 'f1-score': 0.12470939118053101, 'support': 1050.0}, 'weighted avg': {'precision': 0.12491296841372383, 'recall': 0.12761904761904763, 'f1-score': 0.12470939118053101, 'support': 1050.0}}\n",
      "Training model with sigmoid, rmsprop, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 319ms/step - accuracy: 0.5085 - loss: 1.3275 - val_accuracy: 0.3324 - val_loss: 2.4431\n",
      "Epoch 2/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 282ms/step - accuracy: 0.6807 - loss: 0.8559 - val_accuracy: 0.5438 - val_loss: 1.3384\n",
      "Epoch 3/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 328ms/step - accuracy: 0.7428 - loss: 0.6862 - val_accuracy: 0.6524 - val_loss: 0.9028\n",
      "Epoch 4/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 327ms/step - accuracy: 0.7572 - loss: 0.6177 - val_accuracy: 0.7467 - val_loss: 0.6160\n",
      "Epoch 5/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 325ms/step - accuracy: 0.7979 - loss: 0.5302 - val_accuracy: 0.8057 - val_loss: 0.4892\n",
      "Epoch 6/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 329ms/step - accuracy: 0.8231 - loss: 0.4560 - val_accuracy: 0.8714 - val_loss: 0.3003\n",
      "Epoch 7/7\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 327ms/step - accuracy: 0.8378 - loss: 0.4274 - val_accuracy: 0.8505 - val_loss: 0.3763\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.8191 - loss: 0.4314\n",
      "Accuracy of sigmoid_rmsprop_4_128 model: 0.8304761648178101\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step\n",
      "{'0': {'precision': 0.11320754716981132, 'recall': 0.08, 'f1-score': 0.09375, 'support': 150.0}, '1': {'precision': 0.14615384615384616, 'recall': 0.12666666666666668, 'f1-score': 0.1357142857142857, 'support': 150.0}, '2': {'precision': 0.13690476190476192, 'recall': 0.15333333333333332, 'f1-score': 0.14465408805031446, 'support': 150.0}, '3': {'precision': 0.06338028169014084, 'recall': 0.06, 'f1-score': 0.06164383561643835, 'support': 150.0}, '4': {'precision': 0.09154929577464789, 'recall': 0.08666666666666667, 'f1-score': 0.08904109589041095, 'support': 150.0}, '5': {'precision': 0.11320754716981132, 'recall': 0.16, 'f1-score': 0.13259668508287292, 'support': 150.0}, '6': {'precision': 0.14666666666666667, 'recall': 0.14666666666666667, 'f1-score': 0.14666666666666667, 'support': 150.0}, 'accuracy': 0.11619047619047619, 'macro avg': {'precision': 0.11586713521852657, 'recall': 0.11619047619047618, 'f1-score': 0.11486666528871273, 'support': 1050.0}, 'weighted avg': {'precision': 0.1158671352185266, 'recall': 0.11619047619047619, 'f1-score': 0.11486666528871274, 'support': 1050.0}}\n",
      "Results saved to experiment_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Paths\n",
    "results_csv_path = 'experiment_results.csv'\n",
    "confusion_matrix_folder = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrix_folder, exist_ok=True)\n",
    "\n",
    "# Prepare the results DataFrame\n",
    "columns = ['activation', 'optimizer', 'num_layers', 'neurons', 'accuracy', 'precision', 'recall', 'f1_score']\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for activation in activations:\n",
    "    for optimizer in optimizers:\n",
    "        \n",
    "        print(f\"Training model with {activation}, {optimizer}, {num_layers} layers, {neurons} neurons, batch size {batch_size}\")\n",
    "\n",
    "       \n",
    "        model = build_custom_cnn(activation=activation, optimizer=optimizer, num_layers=num_layers, neurons=neurons)\n",
    "        \n",
    "        # Train the model with callbacks\n",
    "        model.fit(\n",
    "            train_generator,\n",
    "            epochs=7,\n",
    "            validation_data=validation_generator,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate the model\n",
    "        test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "        print(f\"Accuracy of {activation}_{optimizer}_{num_layers}_{neurons} model: {test_accuracy}\")\n",
    "\n",
    "        # Get true and predicted labels\n",
    "        y_true = test_generator.classes\n",
    "        y_pred_probs = model.predict(test_generator)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "        # Print the classification report\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        print(report)\n",
    "\n",
    "        # Store the results in DataFrame\n",
    "        results_df = pd.concat([results_df, pd.DataFrame({\n",
    "            'activation': [activation],\n",
    "            'optimizer': [optimizer],\n",
    "            'num_layers': [num_layers],\n",
    "            'neurons': [neurons],\n",
    "            'accuracy': [test_accuracy],\n",
    "            'precision': [precision],  \n",
    "            'recall': [recall],\n",
    "            'f1_score': [f1]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        # # Generate and save confusion matrix\n",
    "        # cm = confusion_matrix(y_true, y_pred)\n",
    "        # plt.figure(figsize=(10, 7))\n",
    "        # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n",
    "        # plt.ylabel('True label')\n",
    "        # plt.xlabel('Predicted label')\n",
    "        # plt.title(f'Confusion Matrix: {activation}, {optimizer}, Layers: {num_layers}, Neurons: {neurons}')\n",
    "        # plt.savefig(os.path.join(confusion_matrix_folder, f'{activation}_{optimizer}_{neurons}_{num_layers}.png'))\n",
    "        # plt.close()\n",
    "\n",
    "# Save all experiment results to CSV\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "print(f\"Results saved to {results_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with relu, adam, 4 layers, 128 neurons, batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 26/307\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 302ms/step - accuracy: 0.1686 - loss: 3.2504"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m build_custom_cnn(activation\u001b[38;5;241m=\u001b[39mactivation, optimizer\u001b[38;5;241m=\u001b[39moptimizer, num_layers\u001b[38;5;241m=\u001b[39mnum_layers, neurons\u001b[38;5;241m=\u001b[39mneurons)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model with callbacks\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m   \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     28\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_generator, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#error\n",
    "results_csv_path = 'experiment_results.csv'\n",
    "confusion_matrix_folder = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrix_folder, exist_ok=True)\n",
    "\n",
    "# Prepare the results DataFrame\n",
    "columns = ['activation', 'optimizer', 'num_layers', 'neurons', 'accuracy', 'precision', 'recall', 'f1_score']\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Run experiments\n",
    "for activation in activations:\n",
    "    for optimizer in optimizers:\n",
    "        \n",
    "                print(f\"Training model with {activation}, {optimizer}, {num_layers} layers, {neurons} neurons, batch size {batch_size}\")\n",
    "\n",
    "                # Build the model (assuming a function build_custom_cnn is defined)\n",
    "                model = build_custom_cnn(activation=activation, optimizer=optimizer, num_layers=num_layers, neurons=neurons)\n",
    "                \n",
    "                # Train the model with callbacks\n",
    "                model.fit(\n",
    "                    train_generator,\n",
    "                    epochs=7,\n",
    "                    validation_data=validation_generator,\n",
    "                   \n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                # Evaluate the model\n",
    "                test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "                print(f\"Accuracy of {activation}_{optimizer}_{num_layers}_{neurons} model: {test_accuracy}\")\n",
    "\n",
    "                # Get true and predicted labels\n",
    "                y_true = test_generator.classes\n",
    "                y_pred_probs = model.predict(test_generator)\n",
    "                y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "                # Calculate precision, recall, and F1 score\n",
    "                precision = precision_score(y_true, y_pred, average='weighted')\n",
    "                recall = recall_score(y_true, y_pred, average='weighted')\n",
    "                f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "                # Print the classification report\n",
    "                report = classification_report(y_true, y_pred, output_dict=True)\n",
    "                print(report)\n",
    "\n",
    "                # Store the results in DataFrame\n",
    "                results_df = results_df.concat({\n",
    "                    'activation': activation,\n",
    "                    'optimizer': optimizer,\n",
    "                    'num_layers': num_layers,\n",
    "                    'neurons': neurons,\n",
    "                    'accuracy': test_accuracy,\n",
    "                    'precision': report['accuracy'],  # Use overall accuracy from the report\n",
    "                    'recall': report['weighted avg']['recall'],\n",
    "                    'f1_score': report['weighted avg']['f1-score']\n",
    "                }, ignore_index=True)\n",
    "\n",
    "                # Generate and save confusion matrix\n",
    "                cm = confusion_matrix(y_true, y_pred)\n",
    "                plt.figure(figsize=(10, 7))\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n",
    "                plt.ylabel('True label')\n",
    "                plt.xlabel('Predicted label')\n",
    "                plt.title(f'Confusion Matrix: {activation}, {optimizer}, Layers: {num_layers}, Neurons: {neurons}')\n",
    "                plt.savefig(os.path.join(confusion_matrix_folder, f'{activation}_{optimizer}_{neurons}_{num_layers}.png'))\n",
    "                plt.close()\n",
    "\n",
    "# Save all experiment results to CSV\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "print(f\"Results saved to {results_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
